{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220419_CNN應用于文本任務.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmfarzMjYSQN7YNXmAh1uo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phyop/220505_TensorFlow2/blob/main/220419_CNN%E6%87%89%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E4%BB%BB%E5%8B%99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "https://www.bilibili.com/video/BV1w44y1k7X6?p=72\n",
        "\n",
        "CNN的輸入是(batch, height, width, channel)，\n",
        "所以如果把文本也變成這樣的格式做輸入，那就也可以用CNN的模型來訓練文本了。\n",
        "所以可以把原本圖像conv的3*3或5*5，改成1*5(1個詞*5維詞向量)之類的就好了。\n",
        "\n",
        "但接連而來的問題是，word是有先後順序的，那這就和圖像有根本上的區別了啊！\n",
        "以7*5的input， \"I like this movie very much !\" 來說，\n",
        "如果改成2*5(2個詞*5維詞向量)之類的，\n",
        "這樣I like這兩個詞就會有先後的關係被連在一起了。\n",
        "以1個詞的步長去走，那下次關聯的詞就會變成like this，\n",
        "再下次就是this movie，\n",
        "那words之間的關聯性就建立起來了。\n",
        "\n",
        "假如設計A、B、C三組不同大小的conv，\n",
        "4*5(短句組成)、3*5(3詞才關聯也不算少)、2*5(2詞關聯相接是最多的)，\n",
        "那對前後文來說，就等同是從大局看到細節的特征都抓到了。\n",
        "\n",
        "越多的conv，就會得到越多的特征圖，也就是截取到的特征就越多。\n",
        "所以把這3組不同大小的conv，一組各做2個，變A1、A2、B1、B2、C1、C2，\n",
        "就類似一般圖像CNN，也是有數個3*3的卷積核，去跑出多張特征圖一樣。\n",
        "因為初始化參數影響未來發展很大，所以就這樣讓各組內部給定不同的初始化參數，\n",
        "這樣A1、A2雖然視野大小相同，但發展方向就會不同，從而截取到不同的特征。\n",
        "而越深入的層，就會截取到越細節。\n",
        "\n",
        "卷積核越小，因為步長可以走的比較多，所以得到的的特征長度就越長。\n",
        "那新的問題就是，這3組conv出來的特征圖，大小就不一樣，沒辦法合在一起。\n",
        "而且文本特征圖都是詞向量，又不像圖像CNN，可以勉強看不出個直線、圖案什麼的，\n",
        "所以我們就把文本conv出來的特征圖，都做max_pooling得到只有一個值，那大小就相同了。\n",
        "\n",
        "然後把各個conv出來的結果，都做完max_pooling後，全部拼接在一起，\n",
        "變成一個單純的一維向量特征結果，後面再接上幾個分類，比如正負評價2類，\n",
        "這就變成一個全連接層，可以做softmax去做分類了。\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "COqCx4pnfG7v",
        "outputId": "920f951d-4842-4547-816b-46920ed58d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhttps://www.bilibili.com/video/BV1w44y1k7X6?p=72\\n\\nCNN的輸入是(batch, height, width, channel)，\\n所以如果把文本也變成這樣的格式做輸入，那就也可以用CNN的模型來訓練文本了。\\n所以可以把原本圖像conv的3*3或5*5，改成1*5(1個詞*5維詞向量)之類的就好了。\\n\\n但接連而來的問題是，word是有先後順序的，那這就和圖像有根本上的區別了啊！\\n以7*5的input， \"I like this movie very much !\" 來說，\\n如果改成2*5(2個詞*5維詞向量)之類的，\\n這樣I like這兩個詞就會有先後的關係被連在一起了。\\n以1個詞的步長去走，那下次關聯的詞就會變成like this，\\n再下次就是this movie，\\n那words之間的關聯性就建立起來了。\\n\\n假如設計A、B、C三組不同大小的conv，\\n4*5(短句組成)、3*5(3詞才關聯也不算少)、2*5(2詞關聯相接是最多的)，\\n那對前後文來說，就等同是從大局看到細節的特征都抓到了。\\n\\n越多的conv，就會得到越多的特征圖，也就是截取到的特征就越多。\\n所以把這3組不同大小的conv，一組各做2個，變A1、A2、B1、B2、C1、C2，\\n就類似一般圖像CNN，也是有數個3*3的卷積核，去跑出多張特征圖一樣。\\n因為初始化參數影響未來發展很大，所以就這樣讓各組內部給定不同的初始化參數，\\n這樣A1、A2雖然視野大小相同，但發展方向就會不同，從而截取到不同的特征。\\n而越深入的層，就會截取到越細節。\\n\\n卷積核越小，因為步長可以走的比較多，所以得到的的特征長度就越長。\\n那新的問題就是，這3組conv出來的特征圖，大小就不一樣，沒辦法合在一起。\\n而且文本特征圖都是詞向量，又不像圖像CNN，可以勉強看不出個直線、圖案什麼的，\\n所以我們就把文本conv出來的特征圖，都做max_pooling得到只有一個值，那大小就相同了。\\n\\n然後把各個conv出來的結果，都做完max_pooling後，全部拼接在一起，\\n變成一個單純的一維向量特征結果，後面再接上幾個分類，比如正負評價2類，\\n這就變成一個全連接層，可以做softmax去做分類了。\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jOW-wYxVyXt",
        "outputId": "3c3f87ee-cfa7-4805-b8b2-9650d1ad35c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ],
      "source": [
        "# 數值數據、圖像、文本都要做預處理\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # 填充\n",
        "# import越細項的，寫在越後面，因為蓋過去大項不會有影響。反之，可能會出現影響。\n",
        "\n",
        "num_features = 3000 # 3000個不同的詞\n",
        "# 文章序列長度。影評是一篇一篇的，詞長度不滿300的，就拿0來填充\n",
        "# 多的截斷，少的補零\n",
        "sequence_length = 300 # 句子長度是300個詞\n",
        "embedding_dimension = 100 # 詞向量維度是100\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=num_features)\n",
        "print(x_train.shape) # (25000,)\n",
        "print(x_test.shape) # (25000,)\n",
        "print(y_train.shape) # (25000,)\n",
        "print(y_test.shape) # (25000,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=sequence_length)\n",
        "x_test = pad_sequences(x_test, maxlen=sequence_length)\n",
        "print(x_train.shape) # (25000, 300)\n",
        "print(x_test.shape) # (25000, 300)\n",
        "# 句子有長短不同，所以才需要填充\n",
        "# label的長度就都很固定，正負評價就是一個數字而已，要嘛0要嘛1\n",
        "# 所以要寫成(25000)，或是(25000, 1)都可以，看計算的維度需要來做reshape\n",
        "print(y_train.shape) # (25000)\n",
        "print(y_test.shape) # (25000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLfIDCaEiHp5",
        "outputId": "54086739-cce3-437b-988e-7af528c855cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 300)\n",
            "(25000, 300)\n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 做3種卷積核，(幾個連續的詞, 詞向量維度) ->（3, 100）、（4, 100）、（5, 100）\n",
        "filter_sizes = [3, 4, 5]\n",
        "# 定義給cnn_mulfilter()用的輔助函數\n",
        "def convolution():\n",
        "    # 回想圖像的卷積是3個維度的，黑白圖第3維的channel是1，彩色有3個channel的深度疊合\n",
        "    # 文本沒有channel的疊合，所以第3維的channel也是1\n",
        "    # 輸入是(句長100, 詞向量300, 符合CNN多加的維度1)\n",
        "    inn = layers.Input(shape=(sequence_length, embedding_dimension, 1))\n",
        "    cnns = []\n",
        "\n",
        "    for size in filter_sizes: # 用不同大小的卷積核去遍歷\n",
        "        # filters=64就是用1個conv去做，會得到64張特征圖\n",
        "        # kernel_size=(3, 100)，就是取3個連續詞的全部詞向量\n",
        "        # tf中的padding='valid'，不会在原有输入的基础上添加新的像素。经过滤波器后可能会变小。\n",
        "        conv = layers.Conv2D(filters=64, kernel_size=(size, embedding_dimension), \n",
        "                            strides=1, padding='valid', activation='relu')(inn)\n",
        "        # 單一個conv，核大小3，步長1，就是把(3, 100)去變成一張特征圖\n",
        "        # 然後取MaxPool，濃縮成一個值\n",
        "        # 所以一整張300個詞句長的詞向量大表都做完後，把每一個conv濃縮的值上下連在一起\n",
        "        # 就會得到一長條 300-3+1 的特征圖，這個直觀上來看的結果，和公式結果是一樣的\n",
        "        # n_out = (h,w - F + 2P)/S + 1 -> (句長300 - 卷積核大小3 + 填充2*0)/步長1 + 1\n",
        "        # pool_size=(300-3+1, 1)，後面那個1，是為了把上下長條特征圖，轉成2D的shape\n",
        "        # 做完所有conv後的(h, w)是(300-3+1, 1)\n",
        "        # 然後再對這個(300-3+1, 1)的pool_size，再去做一次MaxPool2D\n",
        "        # 所以用核大小3，去對300個詞句長的大表做conv，最後就只得到一個值而已\n",
        "        # 但因為filters=64，所以會有平行的64張特征圖，各特征圖最後都有一個值 \n",
        "        # 所以一個卷積核，經過MaxPool後，會得到64個特征值\n",
        "        pool = layers.MaxPool2D(pool_size=(sequence_length - size + 1, 1), padding='valid')(conv)\n",
        "        # 一個卷積核有64個特征值，經過3個卷積核，所以就用list去存放這64*3個特征值\n",
        "        cnns.append(pool)\n",
        "        # 如果在這一層的最後出現indention error，但前後行都找不到錯誤，那就往上一層的for開始檢查\n",
        "        # beautiful code貼過來也錯的話，可以用全選的方式，看有幾個空格，以及tab是不是變成 \"-->\" 這樣的符號\n",
        "\n",
        "    # 然後把所有從卷積核出來的特征值，用concatenate做拼接，得到192個特征\n",
        "    outt = layers.concatenate(cnns)\n",
        "    # 輸入是(句長100, 詞向量300, 符合CNN多加的維度1)\n",
        "    # 輸出是3個卷積核，各得出的64個特征值，拼接而成的192個特征值\n",
        "    model = keras.Model(inputs=inn, outputs=outt)\n",
        "    return model\n",
        "\n",
        "def cnn_mulfilter():\n",
        "    model = keras.Sequential([\n",
        "        # 沒設batch所以None，句子長度是300個詞，詞向量維度是100\n",
        "        #  Layer (type)                Output Shape              Param #   \n",
        "        #  embedding_6 (Embedding)     (None, 300, 100)          300000   \n",
        "        layers.Embedding(input_dim=num_features, output_dim=embedding_dimension, # output_dim (None, 300, 100)\n",
        "                        input_length=sequence_length), # input_length 300\n",
        "        # 在正常情况下，好像都默许了类名首字母大写，而实例用小写的这一准则。\n",
        "        # 但有一些内置的类，首字母都是小写，而实例都是大写。\n",
        "        # 比如 bool 是类名，而 True，False 是其实例；\n",
        "        # 比如 ellipsis 是类名，Ellipsis是实例；\n",
        "        # 还有 int，string，float，list，tuple，dict 等一系列数据类型都是类名，它们都是小写。\n",
        "        # 因為CNN的輸入要求的是3D，所以要用reshape去把本來的2D多加1個維度\n",
        "        # 而多加的那個，維度自然就是1了\n",
        "        # reshape_6 (Reshape)         (None, 300, 100, 1)       0\n",
        "        # (batch, 句長, 詞向量, channel數) -> (None, 300, 100, 1)\n",
        "        # channel數等於1，意義上就類比於黑白圖\n",
        "        layers.Reshape((sequence_length, embedding_dimension, 1)),\n",
        "        # 建立model(輸入句長300的詞向量表，經過conv、maxpool後，輸出192個特征值)\n",
        "        convolution(), \n",
        "        #  model_2 (Functional)        (None, 1, 1, 192)         76992 \n",
        "        # 之前做完maxpool的輸出是3D的(1, 1, 192)\n",
        "        # 因為要全連接去分類，所以要把192個特征值拉平\n",
        "        layers.Flatten(),\n",
        "        # 拉平之後，接多個神經元的dense，再接分類，是定版的結尾\n",
        "        layers.Dense(10, activation='relu'),\n",
        "        # 如果(0.2)寫成(0,2)，就會出現type error\n",
        "        # 所以如果有type error，但哪裡都找不到，就可以注意「小數點\".\"，以及\",\"」\n",
        "        layers.Dropout(0.2), \n",
        "        # 做二分類，所以用一個神經元，搭配sigmoid就可以了\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(),loss=keras.losses.BinaryCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = cnn_mulfilter()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2WpmIAm8KR",
        "outputId": "bade9431-49cd-434e-9dca-3b21406be1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 300, 100)          300000    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 300, 100, 1)       0         \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 1, 1, 192)         76992     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 192)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1930      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 378,933\n",
            "Trainable params: 378,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " embedding (Embedding)       (None, 300, 100)          300000    \n",
        "                                                                 \n",
        " reshape (Reshape)           (None, 300, 100, 1)       0         \n",
        "                                                                 \n",
        " model (Functional)          (None, 1, 1, 192)         76992     \n",
        "                                                                 \n",
        " flatten (Flatten)           (None, 192)               0         \n",
        "                                                                 \n",
        " dense (Dense)               (None, 10)                1930      \n",
        "                                                                 \n",
        " dropout (Dropout)           (None, 10)                0         \n",
        "                                                                 \n",
        " dense_1 (Dense)             (None, 1)                 11        \n",
        "                                                                 \n",
        "=================================================================\n",
        "Total params: 378,933\n",
        "Trainable params: 378,933\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "tLp7p7KvEa9V",
        "outputId": "8aa7b852-908a-41ba-c094-b2397161be05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nModel: \"sequential\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n embedding (Embedding)       (None, 300, 100)          300000    \\n                                                                 \\n reshape (Reshape)           (None, 300, 100, 1)       0         \\n                                                                 \\n model (Functional)          (None, 1, 1, 192)         76992     \\n                                                                 \\n flatten (Flatten)           (None, 192)               0         \\n                                                                 \\n dense (Dense)               (None, 10)                1930      \\n                                                                 \\n dropout (Dropout)           (None, 10)                0         \\n                                                                 \\n dense_1 (Dense)             (None, 1)                 11        \\n                                                                 \\n=================================================================\\nTotal params: 378,933\\nTrainable params: 378,933\\nNon-trainable params: 0\\n_________________________________________________________________\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(資料, label, batch, epochs, 拿多少比例當做驗證集)\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffx9Z_cs_5iv",
        "outputId": "045eb19e-f10a-4b3b-8577-a70fbc4f875f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "352/352 [==============================] - 134s 378ms/step - loss: 0.4734 - accuracy: 0.7621 - val_loss: 0.3334 - val_accuracy: 0.8612\n",
            "Epoch 2/5\n",
            "352/352 [==============================] - 132s 375ms/step - loss: 0.2762 - accuracy: 0.8920 - val_loss: 0.2795 - val_accuracy: 0.8868\n",
            "Epoch 3/5\n",
            "352/352 [==============================] - 125s 355ms/step - loss: 0.1986 - accuracy: 0.9297 - val_loss: 0.3075 - val_accuracy: 0.8828\n",
            "Epoch 4/5\n",
            "352/352 [==============================] - 127s 360ms/step - loss: 0.1405 - accuracy: 0.9549 - val_loss: 0.3091 - val_accuracy: 0.8876\n",
            "Epoch 5/5\n",
            "352/352 [==============================] - 122s 348ms/step - loss: 0.0913 - accuracy: 0.9740 - val_loss: 0.3353 - val_accuracy: 0.8800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "\"\"\"\n",
        "Epoch 1/5\n",
        "352/352 [==============================] - 134s 378ms/step - loss: 0.4734 - accuracy: 0.7621 - val_loss: 0.3334 - val_accuracy: 0.8612\n",
        "Epoch 2/5\n",
        "352/352 [==============================] - 132s 375ms/step - loss: 0.2762 - accuracy: 0.8920 - val_loss: 0.2795 - val_accuracy: 0.8868\n",
        "Epoch 3/5\n",
        "352/352 [==============================] - 125s 355ms/step - loss: 0.1986 - accuracy: 0.9297 - val_loss: 0.3075 - val_accuracy: 0.8828\n",
        "Epoch 4/5\n",
        "352/352 [==============================] - 127s 360ms/step - loss: 0.1405 - accuracy: 0.9549 - val_loss: 0.3091 - val_accuracy: 0.8876\n",
        "Epoch 5/5\n",
        "352/352 [==============================] - 122s 348ms/step - loss: 0.0913 - accuracy: 0.9740 - val_loss: 0.3353 - val_accuracy: 0.8800\n",
        "\n",
        "\"\"\"\n",
        "##########################################################"
      ],
      "metadata": {
        "id": "UebVVCnBIhmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Y92yoVw_KYzx",
        "outputId": "055ead1a-1ef9-4374-9b66-ebb25e2f1f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "\"\"\"\n",
        "《卷积三种模式》\n",
        "https://zhuanlan.zhihu.com/p/62760780\n",
        "\n",
        "三种不同模式是对卷积核移动范围的不同限制。\n",
        "\n",
        "# full模式的意思是，从filter和image刚相交开始做卷积，白色部分为填0。\n",
        "\n",
        "# same mode\n",
        "当filter的中心(K)与image的边角重合时，开始做卷积运算，\n",
        "可见filter的运动范围比full模式小了一圈。\n",
        "注意：这里的same还有一个意思，卷积之后输出的feature map尺寸保持不变(相对于输入图片)。\n",
        "当然，same模式不代表完全输入输出尺寸一样，也跟卷积核的步长有关系。\n",
        "same模式也是最常见的模式，因为这种模式可以在前向传播的过程中让特征图的大小保持不变，\n",
        "调参师不需要精准计算其尺寸变化(因为尺寸根本就没变化)。\n",
        "\n",
        "# 当filter全部在image里面的时候，进行卷积运算，可见filter的移动范围较same更小了。\n",
        "\n",
        "输入图片大小W×W\n",
        "Filter大小F×F\n",
        "步长S\n",
        "padding的像素数P\n",
        "N = (W − F+ 2P)/S+1 输出大小为N×N\n",
        "\n",
        "\n",
        "# tf的padding有两个值，一个是SAME，一个是VALID\n",
        "\n",
        "# 如果padding设置为SAME\n",
        "则说明输入图片大小和输出图片大小是一致的，\n",
        "padding = “SAME”输入和输出大小关系：\n",
        "输出大小等于输入大小除以步长向上取整\n",
        "\n",
        "# 如果是VALID则图片经过滤波器后可能会变小。\n",
        "conv2d的VALID方式不会在原有输入的基础上添加新的像素。\n",
        "n_out = (n_in - f + 1)/s\n",
        "向上取整\n",
        "\n",
        "\"\"\"\n",
        "##########################################################"
      ],
      "metadata": {
        "id": "iClT3iETLCZo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}